"""
Offline AI Code Generator â€” Streaming ChatGPT Style
Run:
    streamlit run app.py
"""

import os
import streamlit as st

from config import OUTPUT_DIR
from model_loader import ModelLoader
from rag_engine import RAGEngine
from code_generator import CodeGenerator
from project_generator import ProjectGenerator


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Page Setup
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Offline AI Code Generator", page_icon="ğŸ¤–")
st.title("ğŸ¤– Offline AI Code Generator")
st.caption("CodeLlama Â· Fully Offline Â· RAG-Enhanced Â· Streaming Enabled")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Cached System Loader
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner=True)
def load_system():
    loader = ModelLoader()
    loader.load()

    rag = RAGEngine()
    rag.initialize()

    generator = CodeGenerator(loader, rag)
    project_gen = ProjectGenerator()

    return loader, rag, generator, project_gen


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Safe Session Initialization
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "initialized" not in st.session_state:

    loader, rag, generator, project_gen = load_system()

    st.session_state.loader = loader
    st.session_state.rag = rag
    st.session_state.generator = generator
    st.session_state.project_gen = project_gen
    st.session_state.messages = []
    st.session_state.initialized = True


os.makedirs(OUTPUT_DIR, exist_ok=True)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sidebar Controls
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:

    st.header("Controls")

    if st.button("ğŸ§¹ Clear Conversation"):
        st.session_state.generator.conversation_history.clear()
        st.session_state.messages = []
        st.rerun()

    st.markdown("---")
    st.markdown("### Commands")
    st.markdown(
        """
        `/project <desc>` â€” Generate full project  
        `/add <file>` â€” Add file to knowledge base  
        `/clear` â€” Clear conversation  
        `/quit` â€” Reload page  
        """
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Display Chat History
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Project Handler
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def handle_project(description: str):

    generator = st.session_state.generator
    project_gen = st.session_state.project_gen

    with st.spinner("Generating project..."):
        files = generator.generate_project(description)

    response_text = ""

    for filepath, content in files.items():
        response_text += (
            f"\n### ğŸ“„ {filepath}\n"
            f"```{filepath.split('.')[-1]}\n"
            f"{content}\n```\n"
        )

    project_name = "_".join(description.split()[:3]).lower()
    project_gen.save_project(project_name, files)

    return response_text


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Add File Handler
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def handle_add(filepath: str):

    rag = st.session_state.rag

    if not os.path.isfile(filepath):
        return f"âŒ File not found: `{filepath}`"

    with open(filepath, "r", encoding="utf-8", errors="ignore") as f:
        content = f.read()

    rag.add_code_file(filepath, content)
    return f"âœ… Added `{filepath}` to knowledge base"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streaming Chat Handler
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def stream_chat_response(prompt: str):

    generator = st.session_state.generator

    response_text = ""

    # Create assistant message container
    with st.chat_message("assistant"):
        message_placeholder = st.empty()

        # Stream tokens directly
        for chunk in generator.stream_inference(
            generator._build_prompt(
                user_msg=prompt,
                rag_context=generator.rag.query(prompt),
                project_context=generator._retrieve_project_context(prompt),
            )
        ):
            response_text += chunk
            message_placeholder.markdown(response_text + "â–Œ")

        # Final render without cursor
        message_placeholder.markdown(response_text)

    return response_text


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Chat Input
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if prompt := st.chat_input("Ask for code or generate a project..."):

    generator = st.session_state.generator

    # Store user message
    st.session_state.messages.append(
        {"role": "user", "content": prompt}
    )

    with st.chat_message("user"):
        st.markdown(prompt)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Command Routing
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if prompt.lower() == "/clear":
        generator.conversation_history.clear()
        st.session_state.messages = []
        st.rerun()

    elif prompt.lower().startswith("/project "):
        description = prompt[9:].strip()
        response = handle_project(description)

        with st.chat_message("assistant"):
            st.markdown(response)

    elif prompt.lower().startswith("/add "):
        filepath = prompt[5:].strip()
        response = handle_add(filepath)

        with st.chat_message("assistant"):
            st.markdown(response)

    elif prompt.lower() in ("/quit", "/exit"):
        response = "ğŸ‘‹ Goodbye! Refresh the page to restart."
        with st.chat_message("assistant"):
            st.markdown(response)
        st.stop()

    else:
        # ğŸ”¥ REAL STREAMING
        response = stream_chat_response(prompt)

        # Update generator memory AFTER streaming
        generator.conversation_history.append(
            {"role": "user", "content": prompt}
        )
        generator.conversation_history.append(
            {"role": "assistant", "content": response}
        )

        generator.rag.add_conversation(prompt, response)

    # Save assistant message to session history
    st.session_state.messages.append(
        {"role": "assistant", "content": response}
    )